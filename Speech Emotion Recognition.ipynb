{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Download the Dataset and Understand the Format","metadata":{}},{"cell_type":"code","source":"! pip install pydub\nfrom pydub import AudioSegment\nimport keras\nimport IPython\nimport wave\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nfrom scipy.io import wavfile\nimport os\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom keras.utils import np_utils\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom keras import layers\nfrom keras import models\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport itertools\nfrom keras import backend as K\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_plt_audio(path):\n    audio_sig,sample_rate  = librosa.load(path)#dtrunc(ata.size/sample rate) = audio length\n    #plot wave plot\n    plt.plot(audio_sig)#reading of pressure wave form of peaks and troughs \"negative peaks\"\n    plt.title('Waveplot')\n    plt.xlabel('Time')\n    plt.ylabel('Amplitude')\n    plt.show()\n    #plot frequencies\n    spectrum = np.fft.fft(audio_sig)# we use Fast Fourier Transform not Fourier Transform as our data is discrete \n    frequencies = np.fft.fftfreq(len(spectrum))\n    magnitude = np.abs(spectrum)\n    plt.plot(frequencies[:int(len(magnitude)/2)],spectrum[:int(len(magnitude)/2)])#only plot left half as right half is the same\n    plt.title('Discrete-Fourier Transform')\n    plt.xlabel('Frequency')\n    plt.ylabel('Magnitude')\n    plt.show()\n\n    return  sample_rate, audio_sig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"neutral\")\npath = '../input/speech-emotion-recognition-en/Ravdess/audio_speech_actors_01-24/Actor_01/03-01-01-01-01-01-01.wav'\nsample_rate, audio_sig =load_plt_audio(path)\nIPython.display.Audio(rate= sample_rate,data= audio_sig)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:07.074461Z","iopub.execute_input":"2022-05-11T00:20:07.074723Z","iopub.status.idle":"2022-05-11T00:20:08.719631Z","shell.execute_reply.started":"2022-05-11T00:20:07.074693Z","shell.execute_reply":"2022-05-11T00:20:08.71868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"calm\")\npath = '../input/speech-emotion-recognition-en/Ravdess/audio_speech_actors_01-24/Actor_01/03-01-02-01-01-01-01.wav'\nsample_rate, audio_sig =load_plt_audio(path)\nIPython.display.Audio(rate= sample_rate,data= audio_sig)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:08.722264Z","iopub.execute_input":"2022-05-11T00:20:08.722963Z","iopub.status.idle":"2022-05-11T00:20:09.31884Z","shell.execute_reply.started":"2022-05-11T00:20:08.72291Z","shell.execute_reply":"2022-05-11T00:20:09.317771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"happy\")\npath = '../input/speech-emotion-recognition-en/Ravdess/audio_speech_actors_01-24/Actor_01/03-01-03-01-01-01-01.wav'\nsample_rate, audio_sig =load_plt_audio(path)\nIPython.display.Audio(rate= sample_rate,data= audio_sig)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:09.320498Z","iopub.execute_input":"2022-05-11T00:20:09.320844Z","iopub.status.idle":"2022-05-11T00:20:09.917644Z","shell.execute_reply.started":"2022-05-11T00:20:09.320811Z","shell.execute_reply":"2022-05-11T00:20:09.916783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"sad\")\npath = '../input/speech-emotion-recognition-en/Ravdess/audio_speech_actors_01-24/Actor_01/03-01-04-01-01-01-01.wav'\nsample_rate, audio_sig =load_plt_audio(path)\nIPython.display.Audio(rate= sample_rate,data= audio_sig)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:09.918765Z","iopub.execute_input":"2022-05-11T00:20:09.918997Z","iopub.status.idle":"2022-05-11T00:20:10.534182Z","shell.execute_reply.started":"2022-05-11T00:20:09.918968Z","shell.execute_reply":"2022-05-11T00:20:10.533186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"angry\")\npath = '../input/speech-emotion-recognition-en/Ravdess/audio_speech_actors_01-24/Actor_01/03-01-05-01-01-01-01.wav'\nsample_rate, audio_sig =load_plt_audio(path)\nIPython.display.Audio(rate= sample_rate,data= audio_sig)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:10.535601Z","iopub.execute_input":"2022-05-11T00:20:10.535899Z","iopub.status.idle":"2022-05-11T00:20:11.173222Z","shell.execute_reply.started":"2022-05-11T00:20:10.535863Z","shell.execute_reply":"2022-05-11T00:20:11.172316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"fearful\")\npath = '../input/speech-emotion-recognition-en/Ravdess/audio_speech_actors_01-24/Actor_01/03-01-06-01-01-01-01.wav'\nsample_rate, audio_sig =load_plt_audio(path)\nIPython.display.Audio(rate= sample_rate,data= audio_sig)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:11.174457Z","iopub.execute_input":"2022-05-11T00:20:11.174755Z","iopub.status.idle":"2022-05-11T00:20:11.803679Z","shell.execute_reply.started":"2022-05-11T00:20:11.174724Z","shell.execute_reply":"2022-05-11T00:20:11.80288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"disgust\")\npath = '../input/speech-emotion-recognition-en/Ravdess/audio_speech_actors_01-24/Actor_01/03-01-07-01-01-01-01.wav'\nsample_rate, audio_sig =load_plt_audio(path)\nIPython.display.Audio(rate= sample_rate,data= audio_sig)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:11.805048Z","iopub.execute_input":"2022-05-11T00:20:11.805734Z","iopub.status.idle":"2022-05-11T00:20:12.404756Z","shell.execute_reply.started":"2022-05-11T00:20:11.805693Z","shell.execute_reply":"2022-05-11T00:20:12.403882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"surprised\")\npath = '../input/speech-emotion-recognition-en/Ravdess/audio_speech_actors_01-24/Actor_01/03-01-08-01-01-01-01.wav'\nsample_rate, audio_sig =load_plt_audio(path)\nIPython.display.Audio(rate= sample_rate,data= audio_sig)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:12.408056Z","iopub.execute_input":"2022-05-11T00:20:12.408914Z","iopub.status.idle":"2022-05-11T00:20:13.007942Z","shell.execute_reply.started":"2022-05-11T00:20:12.408864Z","shell.execute_reply":"2022-05-11T00:20:13.006989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"load dataset","metadata":{}},{"cell_type":"code","source":"emotion_ravdess = {\n    '01':'neutral',\n    '02':'calm',\n    '03':'happy',\n    '04':'sad',\n    '05':'angry',\n    '06':'fearful',\n    '07':'disgust',\n    '08':'surprise'}\n\nemotion_crema = {\n    'FEA':'fearful',\n    'NEU':'neutral',\n    'ANG':'angry',\n    'HAP':'happy',\n    'DIS':'disgust',\n    'SAD':'sad'}\n\nemotion_savee = {\n    'f':'fearful',\n    'n':'neutral',\n    'a':'angry',\n    'h':'happy',\n    'd':'disgust',\n    'sa':'sad',\n    'su':'surprise'}\n\nemotion_tess = {\n    'Fear':'fearful',\n    'fear':'fearful',\n    'neutral':'neutral',\n    'angry':'angry',\n    'happy':'happy',\n    'disgust':'disgust',\n    'sad':'sad',\n    'Sad':'sad',\n    'surprise':'surprise',\n    'surprised':'surprise'}\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.009385Z","iopub.execute_input":"2022-05-11T00:20:13.009742Z","iopub.status.idle":"2022-05-11T00:20:13.018403Z","shell.execute_reply.started":"2022-05-11T00:20:13.009698Z","shell.execute_reply":"2022-05-11T00:20:13.017339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np_data = []\n\n#add Ravdess data\ndirectory = '../input/speech-emotion-recognition-en/Ravdess/audio_speech_actors_01-24'\nfor actor in os.scandir(directory):\n    for file in os.scandir(actor.path):\n        emo = emotion_ravdess[file.path.split('-')[-5]]\n\n        np_data.append([file.path , emo])\n\n#add crema data\ndirectory = '../input/speech-emotion-recognition-en/Crema'\nfor file in os.scandir(directory):\n    emo = emotion_crema[file.path.split('_')[2]]\n\n    np_data.append([file.path , emo])\n\n#add Tess data\ndirectory = '../input/speech-emotion-recognition-en/Tess'\nfor folder in os.scandir(directory):\n    emo = emotion_tess[folder.path.split('_')[-1]]\n    for file in os.scandir(folder.path):\n        np_data.append([file.path , emo])\n\n#add Savee data\ndirectory = '../input/speech-emotion-recognition-en/Savee'\nfor file in os.scandir(directory):\n    key = file.path.split('_')[-1][0]\n    if key=='s':\n        key = file.path.split('_')[-1][0:2]\n    emo = emotion_savee[key]\n\n    np_data.append([file.path , emo])\n\ndf = pd.DataFrame(np_data, columns = ['Path', 'Emotion'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.020041Z","iopub.execute_input":"2022-05-11T00:20:13.020863Z","iopub.status.idle":"2022-05-11T00:20:13.569652Z","shell.execute_reply.started":"2022-05-11T00:20:13.020817Z","shell.execute_reply":"2022-05-11T00:20:13.568727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Emotion'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.571318Z","iopub.execute_input":"2022-05-11T00:20:13.571583Z","iopub.status.idle":"2022-05-11T00:20:13.589558Z","shell.execute_reply.started":"2022-05-11T00:20:13.571552Z","shell.execute_reply":"2022-05-11T00:20:13.588378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df2 = df.copy()\n\ndf = df[df.Emotion != \"surprise\"]\ndf = df[df.Emotion != \"calm\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.590855Z","iopub.execute_input":"2022-05-11T00:20:13.591705Z","iopub.status.idle":"2022-05-11T00:20:13.60572Z","shell.execute_reply.started":"2022-05-11T00:20:13.591651Z","shell.execute_reply":"2022-05-11T00:20:13.604233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Emotion'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.607275Z","iopub.execute_input":"2022-05-11T00:20:13.608365Z","iopub.status.idle":"2022-05-11T00:20:13.618803Z","shell.execute_reply.started":"2022-05-11T00:20:13.608311Z","shell.execute_reply":"2022-05-11T00:20:13.61771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.620156Z","iopub.execute_input":"2022-05-11T00:20:13.620949Z","iopub.status.idle":"2022-05-11T00:20:13.625819Z","shell.execute_reply.started":"2022-05-11T00:20:13.620892Z","shell.execute_reply":"2022-05-11T00:20:13.625143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create the Feature Space","metadata":{}},{"cell_type":"code","source":"def load_audio(path):\n    sig, sample_rate = librosa.load(path,offset=0.3)\n    new_siganl = np.zeros(64745)\n    new_siganl[:len(sig)] =  sig[:64745]        \n    return new_siganl,sample_rate","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.627166Z","iopub.execute_input":"2022-05-11T00:20:13.627419Z","iopub.status.idle":"2022-05-11T00:20:13.637534Z","shell.execute_reply.started":"2022-05-11T00:20:13.627389Z","shell.execute_reply":"2022-05-11T00:20:13.636838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"features domain","metadata":{}},{"cell_type":"code","source":"def noise(data, random=False, rate=0.035, threshold=0.075):\n    if random:\n        rate = np.random.random() * threshold\n    noise_amp = rate*np.random.uniform()*np.amax(data)\n    data = data + noise_amp*np.random.normal(size=data.shape[0])\n    return data\n\n\ndef pitch(data, sampling_rate, pitch_factor=0.7, random=False):#make it lower or higher\n    if random:\n        pitch_factor=np.random.random() * pitch_factor\n    return librosa.effects.pitch_shift(data, sampling_rate, (int)(pitch_factor))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.638501Z","iopub.execute_input":"2022-05-11T00:20:13.639077Z","iopub.status.idle":"2022-05-11T00:20:13.6497Z","shell.execute_reply.started":"2022-05-11T00:20:13.639045Z","shell.execute_reply":"2022-05-11T00:20:13.648895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def zcr(data, frame_length=2048, hop_length=512):\n#     zcr = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n#     return np.squeeze(zcr)\n\n\n# def energy(data, frame_length=2048, hop_length=512):\n#     en = np.array([np.sum(np.power(np.abs(data[hop:hop+frame_length]), 2)) for hop in range(0, data.shape[0], hop_length)])\n#     return en / frame_length\n\n\n# def rmse(data, frame_length=2048, hop_length=512):\n#     rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n#     return np.squeeze(rmse)\n\n\n# def entropy_of_energy(data, frame_length=2048, hop_length=512):\n#     energies = energy(data, frame_length, hop_length)\n#     energies /= np.sum(energies)\n\n#     entropy = 0.0\n#     entropy -= energies * np.log2(energies)\n#     return entropy\n\n\n# def spc(data, sr, frame_length=2048, hop_length=512):\n#     spectral_centroid = librosa.feature.spectral_centroid(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n#     return np.squeeze(spectral_centroid)\n\n\n# def spc_flux(data):\n#     isSpectrum = data.ndim == 1\n#     if isSpectrum:\n#         data = np.expand_dims(data, axis=1)\n#     X = np.c_[data[:, 0], data]\n#     af_Delta_X = np.diff(X, 1, axis=1)\n#     vsf = np.sqrt((np.power(af_Delta_X, 2).sum(axis=0))) / X.shape[0]\n\n#     return np.squeeze(vsf) if isSpectrum else vsf\n\n\n# def spc_rollof(data, sr, frame_length=2048, hop_length=512):\n#     spcrollof = librosa.feature.spectral_rolloff(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n#     return np.squeeze(spcrollof)\n\n# def mfcc(data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n#     mfcc_feature = librosa.feature.mfcc(y=data, sr=sr)\n#     return np.squeeze(mfcc_feature.T) if not flatten else np.ravel(mfcc_feature.T)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.650828Z","iopub.execute_input":"2022-05-11T00:20:13.651558Z","iopub.status.idle":"2022-05-11T00:20:13.662457Z","shell.execute_reply.started":"2022-05-11T00:20:13.651488Z","shell.execute_reply":"2022-05-11T00:20:13.661721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def extract_features(data, sr, frame_length=2048, hop_length=512):\n#     result = np.array([])\n#     result = np.hstack((result,\n#                         zcr(data, frame_length, hop_length),\n# #                         np.mean(energy(data, frame_length, hop_length),axis=0),\n# #                         np.mean(entropy_of_energy(data, frame_length, hop_length), axis=0),\n#                         rmse(data, frame_length, hop_length),\n# #                         spc(data, sr, frame_length, hop_length),\n# #                         spc_flux(data),\n# #                         spc_rollof(data, sr, frame_length, hop_length),\n#                          mfcc(data, sr, frame_length, hop_length)\n\n#                                     ))\n#     return result","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.663581Z","iopub.execute_input":"2022-05-11T00:20:13.664288Z","iopub.status.idle":"2022-05-11T00:20:13.679167Z","shell.execute_reply.started":"2022-05-11T00:20:13.664243Z","shell.execute_reply":"2022-05-11T00:20:13.67813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X, Y = [], []\n\n\n# for i in df.index:\n#     sig, sample_rate  = load_audio(df[\"Path\"][i])\n#     features = extract_features(sig,sample_rate)\n#     X.append(features)\n#     Y.append( df['Emotion'][i])\n    \n#     noise_data = noise(sig, random=True)\n#     features2 = extract_features(noise_data, sample_rate)\n#     X.append(features2)\n#     Y.append( df['Emotion'][i])\n    \n#     # data with pitching\n#     pitched_data = pitch(sig, sample_rate, random=True)\n#     features3 = extract_features(pitched_data, sample_rate)\n#     X.append(features3)\n#     Y.append( df['Emotion'][i])\n    \n#     # data with pitching and white_noise\n#     new_data = pitch(sig, sample_rate, random=True)\n#     data_noise_pitch = noise(new_data, random=True)\n#     features4 = extract_features(data_noise_pitch, sample_rate)\n#     X.append(features4)\n#     Y.append( df['Emotion'][i])\n#     if i%100 == 0:\n#         print(i)\n# df_features = pd.DataFrame(X)\n# df_features[\"Emotion\"] = Y","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.680698Z","iopub.execute_input":"2022-05-11T00:20:13.68097Z","iopub.status.idle":"2022-05-11T00:20:13.694246Z","shell.execute_reply.started":"2022-05-11T00:20:13.680938Z","shell.execute_reply":"2022-05-11T00:20:13.693574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_features = df_features.fillna(0)\n# print(df_features.isna().any().sum())","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.69583Z","iopub.execute_input":"2022-05-11T00:20:13.696317Z","iopub.status.idle":"2022-05-11T00:20:13.707708Z","shell.execute_reply.started":"2022-05-11T00:20:13.696281Z","shell.execute_reply":"2022-05-11T00:20:13.706915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_features","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.70891Z","iopub.execute_input":"2022-05-11T00:20:13.70963Z","iopub.status.idle":"2022-05-11T00:20:13.719679Z","shell.execute_reply.started":"2022-05-11T00:20:13.709592Z","shell.execute_reply":"2022-05-11T00:20:13.718431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"mel spectrogram","metadata":{}},{"cell_type":"code","source":"path = '../input/speech-emotion-recognition-en/Tess/YAF_fear/YAF_back_fear.wav'\nsamplerate, audio_sig =load_plt_audio(path)\n\n#Compute a mel-scaled spectrogram.\nmel_signal = librosa.feature.melspectrogram(y=audio_sig, sr=samplerate)\n# gathering the absolute values for all values in our audio_stft \nspectrogram = np.abs(mel_signal)\n# Converting the amplitude to decibels\npower_to_db = librosa.power_to_db(spectrogram, ref=np.max)\n\n\nlibrosa.display.specshow(power_to_db, sr=samplerate, x_axis='time', y_axis='mel', cmap='magma')\nplt.colorbar(label='dB')\nplt.title('Mel-Spectrogram (dB)')\nplt.xlabel('Time')\nplt.ylabel('Mel Scale')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:13.721099Z","iopub.execute_input":"2022-05-11T00:20:13.72228Z","iopub.status.idle":"2022-05-11T00:20:14.515768Z","shell.execute_reply.started":"2022-05-11T00:20:13.722229Z","shell.execute_reply":"2022-05-11T00:20:14.514798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, Y = [], []\n\n\nfor i in df.index:\n    sig, sample_rate  = load_audio(df[\"Path\"][i])\n    mel_signal = librosa.feature.melspectrogram(y=sig, sr=sample_rate)\n    spectrogram = np.abs(mel_signal)\n    power_to_db = librosa.power_to_db(spectrogram, ref=np.max)\n    X.append(power_to_db)\n    Y.append( df['Emotion'][i])\n\n    # data with noise\n    noise_data = noise(sig, random=True)\n    mel_signal = librosa.feature.melspectrogram(y=noise_data, sr=sample_rate)\n    spectrogram = np.abs(mel_signal)\n    power_to_db = librosa.power_to_db(spectrogram, ref=np.max)\n    X.append(power_to_db)\n    Y.append( df['Emotion'][i])\n    \n    # data with pitching\n    pitched_data = pitch(sig, sample_rate, random=True)\n    mel_signal = librosa.feature.melspectrogram(y=pitched_data, sr=sample_rate)\n    spectrogram = np.abs(mel_signal)\n    power_to_db = librosa.power_to_db(spectrogram, ref=np.max)\n    X.append(power_to_db)\n    Y.append( df['Emotion'][i])\n    \n    #data with pitching and white_noise\n    new_data = pitch(sig, sample_rate, random=True)\n    data_noise_pitch = noise(new_data, random=True)\n    mel_signal = librosa.feature.melspectrogram(y=data_noise_pitch, sr=sample_rate)\n    spectrogram = np.abs(mel_signal)\n    power_to_db = librosa.power_to_db(spectrogram, ref=np.max)\n    X.append(power_to_db)\n    Y.append( df['Emotion'][i])\n\n    if i%100 ==0:\n        print(i)\n\nX = np.array(X)\nY = np.array(Y)\nshape = X.shape\nX = X.reshape((X.shape[0],-1))\n# df_features = pd.DataFrame(X)\n# df_features[\"Emotion\"] = Y","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:20:14.517354Z","iopub.execute_input":"2022-05-11T00:20:14.517714Z","iopub.status.idle":"2022-05-11T00:20:59.294646Z","shell.execute_reply.started":"2022-05-11T00:20:14.517668Z","shell.execute_reply":"2022-05-11T00:20:59.293468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(df_features.isna().any().sum())\n# df_features = df_features.fillna(0)\n# print(df_features.isna().any().sum())","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.04064Z","iopub.execute_input":"2022-05-11T00:21:04.040948Z","iopub.status.idle":"2022-05-11T00:21:04.044436Z","shell.execute_reply.started":"2022-05-11T00:21:04.040914Z","shell.execute_reply":"2022-05-11T00:21:04.043736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the Model","metadata":{}},{"cell_type":"markdown","source":"1d - model","metadata":{}},{"cell_type":"code","source":"# X = df_features.drop(labels=\"Emotion\", axis=1)\n# Y = df_features[\"Emotion\"]\n# Y","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.132042Z","iopub.execute_input":"2022-05-11T00:21:04.132768Z","iopub.status.idle":"2022-05-11T00:21:04.13646Z","shell.execute_reply.started":"2022-05-11T00:21:04.132722Z","shell.execute_reply":"2022-05-11T00:21:04.135591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lb = LabelEncoder()\nY = np_utils.to_categorical(lb.fit_transform(Y))\nprint(lb.classes_)\nY","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.151954Z","iopub.execute_input":"2022-05-11T00:21:04.152644Z","iopub.status.idle":"2022-05-11T00:21:04.161254Z","shell.execute_reply.started":"2022-05-11T00:21:04.152605Z","shell.execute_reply":"2022-05-11T00:21:04.160403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42, test_size=0.3, shuffle=True)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.179323Z","iopub.execute_input":"2022-05-11T00:21:04.18004Z","iopub.status.idle":"2022-05-11T00:21:04.208881Z","shell.execute_reply.started":"2022-05-11T00:21:04.18Z","shell.execute_reply":"2022-05-11T00:21:04.208034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42, test_size=0.05, shuffle=True)\nX_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.210622Z","iopub.execute_input":"2022-05-11T00:21:04.210882Z","iopub.status.idle":"2022-05-11T00:21:04.232321Z","shell.execute_reply.started":"2022-05-11T00:21:04.210855Z","shell.execute_reply":"2022-05-11T00:21:04.23136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.233606Z","iopub.execute_input":"2022-05-11T00:21:04.233825Z","iopub.status.idle":"2022-05-11T00:21:04.240241Z","shell.execute_reply.started":"2022-05-11T00:21:04.233798Z","shell.execute_reply":"2022-05-11T00:21:04.239351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardize data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\nX_val = scaler.transform(X_val)\nX_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.2421Z","iopub.execute_input":"2022-05-11T00:21:04.243035Z","iopub.status.idle":"2022-05-11T00:21:04.330116Z","shell.execute_reply.started":"2022-05-11T00:21:04.242989Z","shell.execute_reply":"2022-05-11T00:21:04.329102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # We have to use 2-dimensional CNN which need specifical shape:\nX_train = X_train.reshape((-1,shape[1],shape[2]))\nX_test = X_test.reshape((-1,shape[1],shape[2]))\nX_val = X_val.reshape((-1,shape[1],shape[2]))\n\nX_train = np.expand_dims(X_train, axis=3)\nX_test = np.expand_dims(X_test, axis=3)\nX_val = np.expand_dims(X_val, axis=3)\n\nX_train.shape, X_test.shape, X_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.331551Z","iopub.execute_input":"2022-05-11T00:21:04.331786Z","iopub.status.idle":"2022-05-11T00:21:04.34056Z","shell.execute_reply.started":"2022-05-11T00:21:04.331759Z","shell.execute_reply":"2022-05-11T00:21:04.33963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # We have to use 1-dimensional CNN which need specifical shape:\n# X_train = np.expand_dims(X_train, axis=2)\n# X_val = np.expand_dims(X_val, axis=2)\n# X_test = np.expand_dims(X_test, axis=2)\n# X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.341793Z","iopub.execute_input":"2022-05-11T00:21:04.342463Z","iopub.status.idle":"2022-05-11T00:21:04.350555Z","shell.execute_reply.started":"2022-05-11T00:21:04.342419Z","shell.execute_reply":"2022-05-11T00:21:04.349452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recall_cal(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_cal(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f_score(y_true, y_pred):\n    precision = recall_cal(y_true, y_pred)\n    recall = precision_cal(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.352093Z","iopub.execute_input":"2022-05-11T00:21:04.352889Z","iopub.status.idle":"2022-05-11T00:21:04.361671Z","shell.execute_reply.started":"2022-05-11T00:21:04.35285Z","shell.execute_reply":"2022-05-11T00:21:04.360998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def Res1D(layer_in, n_filters):\n#     x_skip = layer_in\n#     x = layers.Conv1D(n_filters, kernel_size=3, strides=1,padding=\"same\")(layer_in)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation(\"LeakyReLU\")(x)\n#     x = layers.Conv1D(n_filters, kernel_size=3, strides=1,padding=\"same\")(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Add()([x, x_skip])\n#     x = layers.Activation(\"LeakyReLU\")(x)\n#     return x","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.364284Z","iopub.execute_input":"2022-05-11T00:21:04.364949Z","iopub.status.idle":"2022-05-11T00:21:04.372253Z","shell.execute_reply.started":"2022-05-11T00:21:04.364914Z","shell.execute_reply":"2022-05-11T00:21:04.371593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=0\nY=0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" def Res2D(layer_in, n_filters):\n    x_skip = layer_in\n    x = layers.Conv2D(n_filters, kernel_size=(3,3), strides=(1,1),padding=\"same\")(layer_in)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"LeakyReLU\")(x)\n    x = layers.Conv2D(n_filters, kernel_size=(3,3), strides=(1,1),padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Add()([x, x_skip])\n    x = layers.Activation(\"LeakyReLU\")(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.373555Z","iopub.execute_input":"2022-05-11T00:21:04.373832Z","iopub.status.idle":"2022-05-11T00:21:04.388492Z","shell.execute_reply.started":"2022-05-11T00:21:04.373801Z","shell.execute_reply":"2022-05-11T00:21:04.387632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_input = keras.Input((X_train.shape[1],X_train.shape[2],1),  name=\"audio\")\n\nx = layers.Conv2D(128, kernel_size=(3,3), strides=(3,3),padding=\"same\")(model_input)\nx = Res2D(x,128)\nx = layers.MaxPool2D(pool_size=(3,3), strides=(3,3), padding=\"same\")(x)\n\nx = Res2D(x,128)\nx = layers.MaxPool2D(pool_size=(3,3), strides=(3,3), padding=\"same\")(x)\n\nx = layers.Conv2D(256, kernel_size=(3,3), strides=(1,1),padding=\"same\")(x)\nx = Res2D(x,256)\nx = layers.MaxPool2D(pool_size=(3,3), strides=(3,3), padding=\"same\")(x)\n\nx = Res2D(x,256)\nx = layers.MaxPool2D(pool_size=(3,3), strides=(3,3), padding=\"same\")(x)\n\nx = Res2D(x,256)\nx = layers.MaxPool2D(pool_size=(3,3), strides=(3,3), padding=\"same\")(x)\n\nx = Res2D(x,256)\nx = layers.MaxPool2D(pool_size=(3,3), strides=(3,3), padding=\"same\")(x)\n\n\nx = Res2D(x,256)\nx = layers.MaxPool2D(pool_size=(3,3), strides=(3,3), padding=\"same\")(x)\n\n\nx = layers.Conv2D(512, kernel_size=(3,3), strides=(3,3),padding=\"same\")(x)\nx = Res2D(x,512)\nx = layers.MaxPool2D(pool_size=(3,3), strides=(3,3), padding=\"same\")(x)\nx = layers.Conv2D(512, kernel_size=(3,3), strides=(1,1),padding=\"same\")(x)\n\nx = layers.Flatten()(x)\nmodel_output = layers.Dense(6, activation=\"softmax\")(x)\n\n\nmodel = keras.Model(model_input, model_output, name=\"2D-CNN\")\nmodel.summary()\nmodel.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"acc\", f_score])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:04.389763Z","iopub.execute_input":"2022-05-11T00:21:04.39Z","iopub.status.idle":"2022-05-11T00:21:05.049917Z","shell.execute_reply.started":"2022-05-11T00:21:04.389972Z","shell.execute_reply":"2022-05-11T00:21:05.048898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learningratereduction = ReduceLROnPlateau(monitor='val_acc', patience=3,verbose=1, factor=0.5, min_lr=0.00001)\nearlystopping = EarlyStopping(monitor =\"val_acc\", patience = 5, restore_best_weights = True)\n\n\nhistory=model.fit(X_train, y_train, batch_size=64, epochs=50, validation_data=(X_val, y_val),callbacks=[earlystopping,learningratereduction])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:51.08622Z","iopub.execute_input":"2022-05-11T00:21:51.087374Z","iopub.status.idle":"2022-05-11T00:22:09.707184Z","shell.execute_reply.started":"2022-05-11T00:21:51.087328Z","shell.execute_reply":"2022-05-11T00:22:09.70572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy of our model on test data : \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")\n\nfig , ax = plt.subplots(1,2)\ntrain_acc = history.history['acc']\ntrain_loss = history.history['loss']\ntest_acc = history.history['val_acc']\ntest_loss = history.history['val_loss']\n\nfig.set_size_inches(20,6)\nax[0].plot(train_loss, label = 'Training Loss')\nax[0].plot(test_loss , label = 'Testing Loss')\nax[0].set_title('Training & Testing Loss')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\n\nax[1].plot(train_acc, label = 'Training Accuracy')\nax[1].plot(test_acc , label = 'Testing Accuracy')\nax[1].set_title('Training & Testing Accuracy')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:13.37746Z","iopub.status.idle":"2022-05-11T00:21:13.377807Z","shell.execute_reply.started":"2022-05-11T00:21:13.377634Z","shell.execute_reply":"2022-05-11T00:21:13.377651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\ny_pred = np.argmax(y_pred, axis=1)\ny_pred\ny_check = np.argmax(y_test, axis=1)\ny_check\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_true=y_check, y_pred=y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:13.378982Z","iopub.status.idle":"2022-05-11T00:21:13.379277Z","shell.execute_reply.started":"2022-05-11T00:21:13.379128Z","shell.execute_reply":"2022-05-11T00:21:13.379144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\ncm_plot_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:13.380453Z","iopub.status.idle":"2022-05-11T00:21:13.380781Z","shell.execute_reply.started":"2022-05-11T00:21:13.380629Z","shell.execute_reply":"2022-05-11T00:21:13.380647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_input = keras.Input((X_train.shape[1],1),  name=\"audio\")\n\n# x = layers.Conv1D(128, kernel_size=3, strides=3,padding=\"same\")(model_input)\n# x = Res1D(x,128)\n# x = layers.MaxPool1D(pool_size=3, strides=3, padding=\"same\")(x)\n\n# x = Res1D(x,128)\n# x = layers.MaxPool1D(pool_size=3, strides=3, padding=\"same\")(x)\n\n# x = layers.Conv1D(256, kernel_size=3, strides=1,padding=\"same\")(x)\n# x = Res1D(x,256)\n# x = layers.MaxPool1D(pool_size=3, strides=3, padding=\"same\")(x)\n\n# x = Res1D(x,256)\n# x = layers.MaxPool1D(pool_size=3, strides=3, padding=\"same\")(x)\n\n# x = Res1D(x,256)\n# x = layers.MaxPool1D(pool_size=3, strides=3, padding=\"same\")(x)\n\n# x = Res1D(x,256)\n# x = layers.MaxPool1D(pool_size=3, strides=3, padding=\"same\")(x)\n\n\n# x = Res1D(x,256)\n# x = layers.MaxPool1D(pool_size=3, strides=3, padding=\"same\")(x)\n\n\n# x = layers.Conv1D(512, kernel_size=3, strides=1,padding=\"same\")(x)\n# x = Res1D(x,512)\n# x = layers.MaxPool1D(pool_size=3, strides=3, padding=\"same\")(x)\n# x = layers.Conv1D(512, kernel_size=3, strides=1,padding=\"same\")(x)\n\n# x = layers.Flatten()(x)\n# model_output = layers.Dense(6, activation=\"softmax\")(x)\n\n\n# model = keras.Model(model_input, model_output, name=\"1D-CNN\")\n# model.summary()\n# model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"acc\", f_score])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:13.382981Z","iopub.status.idle":"2022-05-11T00:21:13.383279Z","shell.execute_reply.started":"2022-05-11T00:21:13.383119Z","shell.execute_reply":"2022-05-11T00:21:13.383134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_mel = []\n\n# for i in df.index:#change to df\n#     mel_signal = librosa.feature.melspectrogram(y=df['Signal'][i], sr=df['Sample Rate'][i])\n#     spectrogram = np.abs(mel_signal)\n#     power_to_db = librosa.power_to_db(spectrogram, ref=np.max)\n#     df_mel.append([power_to_db , df['Emotion'][i]]) \n    \n# df_mel = pd.DataFrame(df_mel, columns = ['mel spectrogram', 'Emotion'])\n# # for i in df_2d['mel spectrogram']:\n# #     print(i.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T00:21:13.384064Z","iopub.status.idle":"2022-05-11T00:21:13.384335Z","shell.execute_reply.started":"2022-05-11T00:21:13.384197Z","shell.execute_reply":"2022-05-11T00:21:13.384211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}